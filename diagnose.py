#!/usr/bin/env python3
"""
LeakHunterX - Connectivity Test Script
Diagnose why crawler is failing to fetch URLs
"""

import asyncio
import aiohttp
import socket
from urllib.parse import urlparse
from rich.console import Console

console = Console()

async def test_dns_resolution(domain: str) -> bool:
    """Test DNS resolution for a domain"""
    try:
        console.print(f"ğŸ” Testing DNS for: {domain}", style="blue")
        
        # Test IPv4
        try:
            socket.getaddrinfo(domain, 443, family=socket.AF_INET, timeout=5)
            console.print(f"âœ… IPv4 DNS works: {domain}", style="green")
            return True
        except socket.gaierror:
            pass
        
        # Test IPv6
        try:
            socket.getaddrinfo(domain, 443, family=socket.AF_INET6, timeout=5)
            console.print(f"âœ… IPv6 DNS works: {domain}", style="green")
            return True
        except socket.gaierror:
            pass
            
        console.print(f"âŒ DNS failed: {domain}", style="red")
        return False
        
    except Exception as e:
        console.print(f"ğŸ’¥ DNS error for {domain}: {e}", style="red")
        return False

async def test_http_request(url: str, timeout: float = 10.0) -> dict:
    """Test HTTP request with detailed diagnostics"""
    result = {
        'url': url,
        'dns_works': False,
        'status_code': 0,
        'response_time': 0,
        'error': None,
        'headers': {},
        'final_url': url
    }
    
    try:
        parsed = urlparse(url)
        domain = parsed.netloc
        
        # Test DNS first
        result['dns_works'] = await test_dns_resolution(domain)
        if not result['dns_works']:
            result['error'] = "DNS resolution failed"
            return result
        
        # Test HTTP request
        console.print(f"ğŸŒ Testing HTTP: {url}", style="blue")
        
        connector = aiohttp.TCPConnector(ssl=False, limit=1)
        timeout_obj = aiohttp.ClientTimeout(total=timeout)
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        }
        
        start_time = asyncio.get_event_loop().time()
        
        async with aiohttp.ClientSession(
            connector=connector, 
            timeout=timeout_obj,
            headers=headers
        ) as session:
            
            async with session.get(url, ssl=False, allow_redirects=True) as response:
                result['status_code'] = response.status
                result['headers'] = dict(response.headers)
                result['final_url'] = str(response.url)
                
                # Try to read a small part of content
                try:
                    content_sample = await response.text()[:100]
                    result['content_sample'] = content_sample
                except:
                    result['content_sample'] = "Unable to read content"
        
        result['response_time'] = asyncio.get_event_loop().time() - start_time
        
        if result['status_code'] == 200:
            console.print(f"âœ… HTTP 200: {url} ({result['response_time']:.2f}s)", style="green")
        else:
            console.print(f"âš ï¸ HTTP {result['status_code']}: {url}", style="yellow")
            
    except asyncio.TimeoutError:
        result['error'] = f"Timeout after {timeout}s"
        console.print(f"â° Timeout: {url}", style="red")
    except aiohttp.ClientConnectorError as e:
        result['error'] = f"Connection error: {e}"
        console.print(f"ğŸ”Œ Connection error: {url} - {e}", style="red")
    except aiohttp.ClientResponseError as e:
        result['error'] = f"Response error: {e}"
        result['status_code'] = e.status
        console.print(f"ğŸ“¡ Response error: {url} - {e.status}", style="red")
    except Exception as e:
        result['error'] = f"Unexpected error: {e}"
        console.print(f"ğŸ’¥ Unexpected error: {url} - {e}", style="red")
    
    return result

async def test_protocol_fallback(url: str) -> dict:
    """Test both HTTPS and HTTP protocols"""
    results = {}
    
    # Test HTTPS first
    if url.startswith('https://'):
        results['https'] = await test_http_request(url)
        
        # Test HTTP fallback
        http_url = url.replace('https://', 'http://')
        results['http'] = await test_http_request(http_url)
    else:
        results['http'] = await test_http_request(url)
        
        # Test HTTPS
        https_url = url.replace('http://', 'https://')
        results['https'] = await test_http_request(https_url)
    
    return results

async def comprehensive_connectivity_test():
    """Run comprehensive connectivity tests"""
    console.print("\n" + "="*60, style="bold blue")
    console.print("ğŸ”§ LEAKHUNTERX CONNECTIVITY DIAGNOSTICS", style="bold blue")
    console.print("="*60, style="bold blue")
    
    # Test domains - mix of base domain and subdomains
    test_urls = [
        "https://tesla.com",
        "https://www.tesla.com",
        "https://static.tesla.com",
        "https://akamai-apigateway-stg-warpdashboardapi.tesla.com",
        "https://apf-api.eng.vn.cloud.tesla.com",
        "https://digitalassets-accounts.tesla.com",
        "https://origin-bolt.tesla.com",
        "https://origin-finplat-stg.tesla.com"
    ]
    
    all_results = {}
    
    for url in test_urls:
        console.print(f"\nğŸ¯ Testing: {url}", style="bold cyan")
        all_results[url] = await test_protocol_fallback(url)
        
        # Small delay between tests
        await asyncio.sleep(0.5)
    
    # Print summary
    console.print("\n" + "="*60, style="bold blue")
    console.print("ğŸ“Š CONNECTIVITY TEST SUMMARY", style="bold blue")
    console.print("="*60, style="bold blue")
    
    successful_dns = 0
    successful_http = 0
    blocked_403 = 0
    timeouts = 0
    connection_errors = 0
    
    for url, protocols in all_results.items():
        console.print(f"\nğŸ”— {url}", style="bold")
        
        for protocol, result in protocols.items():
            status_emoji = "âœ…" if result.get('status_code') == 200 else "âŒ"
            dns_emoji = "âœ…" if result.get('dns_works') else "âŒ"
            
            if result.get('dns_works'):
                successful_dns += 1
            
            if result.get('status_code') == 200:
                successful_http += 1
            elif result.get('status_code') == 403:
                blocked_403 += 1
            
            if result.get('error'):
                if 'Timeout' in result['error']:
                    timeouts += 1
                elif 'Connection' in result['error']:
                    connection_errors += 1
            
            console.print(f"  {protocol.upper():6} | DNS: {dns_emoji} | HTTP: {status_emoji} {result.get('status_code', 'N/A'):3} | {result.get('error', 'Success')}")
    
    # Overall statistics
    console.print("\n" + "="*60, style="bold blue")
    console.print("ğŸ“ˆ OVERALL STATISTICS", style="bold blue")
    console.print("="*60, style="bold blue")
    
    total_tests = len(test_urls) * 2  # Each URL tested with HTTP and HTTPS
    
    console.print(f"âœ… Successful DNS: {successful_dns}/{total_tests}")
    console.print(f"âœ… Successful HTTP 200: {successful_http}/{total_tests}")
    console.print(f"ğŸš« 403 Blocks: {blocked_403}/{total_tests}")
    console.print(f"â° Timeouts: {timeouts}/{total_tests}")
    console.print(f"ğŸ”Œ Connection Errors: {connection_errors}/{total_tests}")
    
    # Recommendations based on results
    console.print("\n" + "="*60, style="bold blue")
    console.print("ğŸ’¡ RECOMMENDATIONS", style="bold blue")
    console.print("="*60, style="bold blue")
    
    if blocked_403 > total_tests * 0.5:
        console.print("ğŸ”§ ISSUE: High rate of 403 blocks")
        console.print("   â†’ Implement better User-Agent rotation")
        console.print("   â†’ Add request headers randomization")
        console.print("   â†’ Consider using proxies")
        
    if timeouts > total_tests * 0.3:
        console.print("ğŸ”§ ISSUE: Frequent timeouts")
        console.print("   â†’ Increase HTTP timeout values")
        console.print("   â†’ Add retry logic with exponential backoff")
        
    if connection_errors > total_tests * 0.3:
        console.print("ğŸ”§ ISSUE: Connection errors")
        console.print("   â†’ Check network connectivity")
        console.print("   â†’ Verify DNS resolver configuration")
        
    if successful_http == 0:
        console.print("ğŸ”§ ISSUE: No successful HTTP requests")
        console.print("   â†’ Target might be aggressively blocking")
        console.print("   â†’ Consider using residential proxies")
        console.print("   â†’ Add delays between requests")
    else:
        console.print("âœ… Some requests successful - crawler should work with adjustments")

async def test_crawler_components():
    """Test individual crawler components"""
    console.print("\n" + "="*60, style="bold green")
    console.print("ğŸ•·ï¸ CRAWLER COMPONENT TESTS", style="bold green")
    console.print("="*60, style="bold green")
    
    try:
        # Test DomainManager
        console.print("ğŸ”§ Testing DomainManager...", style="blue")
        from modules.domain_manager import DomainManager
        
        dm = DomainManager("tesla.com")
        dm.add_priority_target("https://tesla.com", depth=0, score=100)
        dm.add_priority_target("https://www.tesla.com", depth=0, score=90)
        
        # Get next targets
        url1, depth1 = dm.get_next_target()
        url2, depth2 = dm.get_next_target()
        
        console.print(f"âœ… DomainManager: Got targets - {url1}, {url2}", style="green")
        
        # Mark as complete
        dm.mark_url_complete(url1, success=True)
        dm.mark_url_complete(url2, success=False, error_type="http_error")
        
        stats = dm.get_stats()
        console.print(f"âœ… DomainManager stats: {stats['urls_processed_success']} success, {stats['urls_processed_failure']} failed", style="green")
        
    except Exception as e:
        console.print(f"âŒ DomainManager test failed: {e}", style="red")
    
    try:
        # Test HTTP Client
        console.print("\nğŸ”§ Testing HTTP Client...", style="blue")
        from modules.http_client import AsyncHTTPClient
        
        http_client = AsyncHTTPClient(timeout=10.0, max_retries=1)
        await http_client.init_dns_resolver()
        
        test_url = "https://tesla.com"
        fetched_url, content, status_code, state = await http_client.fetch_with_fallback(test_url)
        
        console.print(f"âœ… HTTP Client: {test_url} â†’ Status: {status_code}, State: {state}", style="green")
        
        await http_client.close()
        
    except Exception as e:
        console.print(f"âŒ HTTP Client test failed: {e}", style="red")

async def main():
    """Main diagnostic function"""
    console.print("ğŸš€ LeakHunterX Connectivity Diagnostics", style="bold magenta")
    console.print("This will identify why the crawler is failing...", style="dim")
    
    # Run comprehensive connectivity tests
    await comprehensive_connectivity_test()
    
    # Test crawler components
    await test_crawler_components()
    
    console.print("\nğŸ‰ Diagnostics complete! Check recommendations above.", style="bold green")

if __name__ == "__main__":
    # Run diagnostics
    asyncio.run(main())
